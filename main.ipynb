{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8762e222",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68edf891",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Определение устройства\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a20734e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Определение класса датасета\n",
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, root_dir, sr=16000, n_mfcc=40, max_len=220):\n",
    "        self.file_paths = []  # список путей к аудиофайлам\n",
    "        self.labels = []      # соответствующие метки классов\n",
    "        self.sr = sr\n",
    "        self.n_mfcc = n_mfcc\n",
    "        self.max_len = max_len  # максимальная длина для паддинга\n",
    "        self._load_dataset(root_dir)\n",
    "\n",
    "    def _load_dataset(self, root_dir):\n",
    "        class_labels = os.listdir(root_dir)\n",
    "        for label_idx, class_label in enumerate(class_labels):\n",
    "            class_dir = os.path.join(root_dir, class_label)\n",
    "            if os.path.isdir(class_dir):\n",
    "                for file_name in os.listdir(class_dir):\n",
    "                    if file_name.endswith('.wav'):\n",
    "                        file_path = os.path.join(class_dir, file_name)\n",
    "                        self.file_paths.append(file_path)\n",
    "                        self.labels.append(label_idx)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.file_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        audio, sr = librosa.load(file_path, sr=self.sr)\n",
    "        mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=self.n_mfcc)\n",
    "        mfcc = (mfcc - np.mean(mfcc)) / np.std(mfcc)\n",
    "\n",
    "        # Паддинг или обрезка\n",
    "        if mfcc.shape[1] < self.max_len:\n",
    "            pad_width = self.max_len - mfcc.shape[1]\n",
    "            mfcc = F.pad(torch.tensor(mfcc, dtype=torch.float32), (0, pad_width))\n",
    "        else:\n",
    "            mfcc = torch.tensor(mfcc, dtype=torch.float32)[:, :self.max_len]\n",
    "\n",
    "        mfcc = mfcc.unsqueeze(0)\n",
    "        return mfcc, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c65b6f3",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Определение модели\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)  # Свёрточный слой 1\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)  # Свёрточный слой 2\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)  # Свёрточный слой 3\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)  # Свёрточный слой 4\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)  # Слой pooling\n",
    "\n",
    "        self.fc1 = None\n",
    "        self.fc2 = None\n",
    "        self.fc3 = None\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # Свёрточный слой 1 и pooling\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # Свёрточный слой 2 и pooling\n",
    "        x = self.pool(F.relu(self.conv3(x)))  # Свёрточный слой 3 и pooling\n",
    "        x = self.pool(F.relu(self.conv4(x)))  # Свёрточный слой 4 и pooling\n",
    "        \n",
    "        if self.fc1 is None or self.fc2 is None or self.fc3 is None:\n",
    "            num_features = x.view(x.size(0), -1).size(1)  # Подготовка к полносвязным слоям\n",
    "            self.fc1 = nn.Linear(num_features, 256).to(device)  # Полносвязный слой 1\n",
    "            self.fc2 = nn.Linear(256, 128).to(device)  # Полносвязный слой 2\n",
    "            self.fc3 = nn.Linear(128, self.num_classes).to(device)  # Полносвязный выходной слой\n",
    "\n",
    "        x = x.view(x.size(0), -1)  # Разворачивание характеристик в одномерный вектор\n",
    "        \n",
    "        x = F.relu(self.fc1(x))  # Полносвязный слой 1 с активацией ReLU\n",
    "        x = F.relu(self.fc2(x))  # Полносвязный слой 2 с активацией ReLU\n",
    "        x = self.fc3(x)  # Полносвязный выходной слой\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfab8a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Использование\n",
    "dataset = AudioDataset(root_dir='data_audio_train')\n",
    "dataloader = DataLoader(dataset, batch_size=500, shuffle=True)\n",
    "\n",
    "num_classes = len(set(dataset.labels))\n",
    "model = CNN(num_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7928ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тренировка модели\n",
    "for epoch in range(50):\n",
    "    for inputs, targets in dataloader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch {epoch+1}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11990f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание тестового датасета\n",
    "test_dataset = AudioDataset(root_dir='data_audio_test')\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=100, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8824b9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тестирование\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_dataloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy of the model on the test data: {accuracy}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fdeae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Собираем все истинные и предсказанные метки\n",
    "true_labels = []\n",
    "pred_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_dataloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        true_labels.extend(labels.cpu().numpy()) \n",
    "        pred_labels.extend(predicted.cpu().numpy())\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(true_labels, pred_labels))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(true_labels, pred_labels))"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
